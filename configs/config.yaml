# MikoEcho Configuration File

# Model Architecture
model:
  name: "MikoEcho"
  
  # Speech Encoder (HuBERT)
  speech_encoder:
    model_name: "facebook/hubert-large-ls960-ft"
    freeze: true
    output_dim: 1024
  
  # Speaker Encoder (ECAPA-TDNN)
  speaker_encoder:
    model_name: "speechbrain/spkrec-ecapa-voxceleb"
    embedding_dim: 192
    freeze: false
  
  # Content Disentangler
  content_disentangler:
    hidden_dim: 512
    num_layers: 4
    dropout: 0.1
  
  # Style Encoder
  style_encoder:
    emotion_dim: 64
    num_emotions: 5  # neutral, calm, excited, sad, energetic
    hidden_dim: 256
  
  # Vocoder (HiFi-GAN)
  vocoder:
    model_name: "hifigan"
    checkpoint: "pretrained/hifigan_v1"
    sample_rate: 22050
    hop_length: 256
    win_length: 1024
    n_fft: 1024
    n_mels: 80

# Training Configuration
training:
  # General
  seed: 42
  num_epochs: 100
  batch_size: 16
  gradient_accumulation_steps: 2
  mixed_precision: true
  
  # Optimization
  optimizer:
    type: "AdamW"
    lr: 0.0001
    betas: [0.9, 0.999]
    weight_decay: 0.01
  
  scheduler:
    type: "CosineAnnealingWarmRestarts"
    T_0: 10
    T_mult: 2
    eta_min: 0.00001
  
  # Loss Weights
  loss_weights:
    reconstruction: 1.0
    speaker_similarity: 0.5
    content_preservation: 0.3
    adversarial: 0.1
    perceptual: 0.2
  
  # Checkpointing
  checkpoint_dir: "checkpoints"
  save_every: 5
  keep_last_n: 3
  
  # Logging
  log_dir: "logs"
  log_every: 100
  tensorboard: true
  wandb: false

# Data Configuration
data:
  # Datasets
  train_datasets:
    - name: "LibriSpeech"
      path: "datasets/librispeech"
      split: "train-clean-360"
    - name: "VCTK"
      path: "datasets/vctk"
      split: "train"
  
  val_datasets:
    - name: "LibriSpeech"
      path: "datasets/librispeech"
      split: "dev-clean"
  
  # Audio Processing
  sample_rate: 22050
  max_duration: 10.0  # seconds
  min_duration: 1.0
  
  # Augmentation
  augmentation:
    enabled: true
    noise_prob: 0.3
    reverb_prob: 0.2
    pitch_shift_range: [-2, 2]  # semitones
    speed_range: [0.9, 1.1]
  
  # DataLoader
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2

# Inference Configuration
inference:
  device: "cuda"  # cuda, cpu, or auto
  batch_size: 1
  
  # Voice Cloning
  reference_duration: [3, 30]  # min, max seconds
  
  # Emotion Control
  emotions:
    - neutral
    - calm
    - excited
    - sad
    - energetic
  
  # Streaming
  streaming:
    enabled: false
    chunk_size: 1.0  # seconds
    overlap: 0.1
  
  # Output
  output_sample_rate: 22050
  output_format: "wav"

# Evaluation Metrics
evaluation:
  metrics:
    - speaker_similarity
    - mos_estimation
    - wer
    - pitch_correlation
  
  speaker_similarity_threshold: 0.85
  mos_threshold: 4.0

# System
system:
  gpu_ids: [0]
  distributed: false
  num_nodes: 1
  world_size: 1
